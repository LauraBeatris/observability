# Structured Logs vs Unstructured Logs 

> Structured data is clearly defined and searchable. Unstructured data isn’t organized in an easily searchable manner and is usually stored in its native format

## Unstructured Logs

Log files are basically a unstructured format of texts, with it's main purpose to be readable by humans, but making it difficult to be processed by machines. These are generated by application/infrastructure systems calls that contain those events records 

As mentioned previously, traditional logs are unstructured because they were designed to be human readable, and often separate the vivid details of one event into multiple lines of text, like so:

```
6:01:00 accepted connection on port 80 from 10.0.0.3:63349
6:01:03 basic authentication accepted for user foo
6:01:15 processing request for /super/slow/server
6:01:18 request succeeded, sent response code 200
6:01:19 closed connection to 10.0.0.3:63349
```

In traditional monolithic systems, human operators had a very small number of services to manage and logs were written to the local disk of the machines where applications ran. Along the years, as systems got more distributed, those no longer run at an easy scale in order for humans to keep up with the possible amount of unstructured logs in order to perform searching

Searching through millions of lines of unstructured logs can be accomplished by using some type of log file parser. Parsers split log data into chunks of information and attempt to group them in meaningful ways. However, with unstructured data, parsing gets complicated because different formatting rules (or no rules at all) exist for different types of log files

Logging tools are full of different approaches to solving this problem, with varying degrees of success, performance, and usability

## Structured Logs
The solution is to instead create structured log data designed for machine parsability

```
time="6:01:00" msg="accepted connection" port="80" authority="10.0.0.3:63349"
time="6:01:03" msg="basic authentication accepted" user="foo"
time="6:01:15" msg="processing request" path="/super/slow/server"
time="6:01:18" msg="sent response code" status="200"
time="6:01:19" msg="closed connection" authority="10.0.0.3:63349"
```

Many logs are only portions of events, regardless of whether those logs are structured

When observability and logging get connected, it helps to understand that an structured event, as a unit of work, should contain information about what it took for a service to perform that execution

Examples of unit of work:
- Downloading a file 
- Parsing a file 
- Extracting specific pieces of information

In the context of services, a unit of work could be accepting an HTTP request and doing everything necessary to return a response. Also other times, one HTTP request can generate many other events during its execution

A structured event should be scoped to contain everything about what it took to perform that unit of work. It should record the input necessary to perform the work, any attributes gathered—whether computed, resolved, or discovered—along the way, the conditions of the service as it was performing the work, and details about the result of the work performed

It’s common to see anywhere from a few to a few dozen log lines or entries that, when taken together, represent what could be considered one unit of work

The goal of observability is to enable you to interrogate your event data in order to understand the internal state of your systems, that's what makes it to be an investigative process. Any data used to do so must be machine-parsable in order to facilitate that goal. Unstructured data is simply unusable for that task. Log data can, however, be useful when redesigned to resemble a structured event, the fundamental building block of observability
